import styles, { layout } from '../style';
import ComputerVision from './ComputerVision';
import { featuresTraining } from '../constants';

const FancyALink = ({ text, link }) => (
  <span onClick={() => window.open(
    link)}
    className='text-secondary cursor-pointer'>{text}</span>
)

const ModelDescription = () =>
(
  <section id='model' className={`${layout.section} items-start`}>
    <div className={`${layout.sectionInfo} relative`}>
      <div className='absolute w-[100%] h-[100%]
      left-[80%] rounded-full blue__gradient'/>
      <h2 className={`${styles.heading2} cursor-pointer`} onClick={() => { window.location.href = '#camera' }} >
        <span className='text-secondary cursor-pointer'>Give it a try!</span></h2>
      <h3 className='font-poppins text-white text-[30px] mt-5'>Training:</h3>
      <p className={`${styles.paragraph} mt-5`}>
        Our model was obtained by performing{' '}
        <FancyALink link='https://www.linkedin.com/pulse/experimental-process-my-first-use-transfer-learning-victoria-delgado/'
          text='transfer learning' />{' '}
        , using the given pertained weights as a feature extractor.{' '}
        This allows for achieving acceptable results using a reduced data set, computational power and training time.{' '}
        The training consisted in fine tuning a{' '}
        <FancyALink link='https://github.com/WongKinYiu/yolov7' text='YOLOv7' /> model{' '}
        in a custom data set created from scratch containing 971 images which lesser of the half were generated by{' '}
        <FancyALink link='https://www.linkedin.com/pulse/data-augmentation-joaquin-victoria-delgado/?trackingId=2qvOy2Lrfhi%2BHem4dDjhrA%3D%3D' text='data augmentation' />
        .<br />The goal was classify whether unhealthy or healthy apples.
      </p>
      <h3 className='font-poppins text-white text-[30px] mt-5'>Results:</h3>
      <p className={`${styles.paragraph} mt-5`}>
        Before talking about the results, we must know what each used metric measurement means.{' '}
        Precision is the True Positives {'('}TP{')'} divided by the TP plus the False Positives {'('}FP{')'}. The Recall is{' '}
        the TP divided by the TP plus the False Negatives {'('}FN{')'}. The Average Precision {'('}AP{')'} is the area under the Precision-Recall curve. And last but not least,{' '}
        the mean Average Precision {'('}mAP{')'} is the AP mean across all the labels. This metrics are computed to know how well our model will perform.{' '}
        Then the Train Loss is the result of the Loss Function across all the training. The Loss Function {'('}known Error Function or Objective Function{')'}{' '}
        is used during the training to update the model's weights. In other words, the model learns from the errors by comparing its outcome with the actual values to improve its future predictions.<br />
        As you can see in the charts, the loss tended to decrease while the precision, recall, and mAP tended to increase. Meaning the training was successful.
      </p>
      <h3 className='font-poppins text-white text-[30px] mt-5'>Conclusion:</h3>
      <p className={`${styles.paragraph} mt-5`}>
      Although it was trained with images extracted from Google Images and sometimes predicts false positives, the model performs well. This means that if trained with labeled images with the supervision of experts, it will improve the performance tremendously.{' '}
      This opens the possibility of discriminating between several diseases without problems with several Fruits/Vegetables.
      </p>
    </div>
    <div className={`${layout.sectionImg} flex-col`}>
      {featuresTraining.map((feature, index) => (
        <ComputerVision key={feature.id} {...feature} index={index} n={featuresTraining.length} />
      ))}
    </div>
  </section>
)

export default ModelDescription;